{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Gabriel Pascua de Freitas Moreira\n",
    "\n",
    "Nome: Fernando Cesar Furtado Ballesteros Fincatti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "#Conta: @gabrielpfm\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "#with open('auth.pass') as fp:    \n",
    " #   data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "#auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "#auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "#produto = 'Nintendo'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "#n = 750\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 450\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "#i = 1\n",
    "#msgs = []\n",
    "#for msg in tweepy.Cursor(api.search, q=produto, lang=lang,tweet_mode=\"extended\").items():    \n",
    "    #msgs.append(msg.full_text.lower())\n",
    " #   i += 1\n",
    " # #  if i > n:\n",
    "   #     break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "#shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "#if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "   # writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "  #  dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "   # dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "  #  dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "  #  dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "  #  writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira Análise\n",
    "Numa primeira análise, serão usadas 3 categorias, sendo elas:\n",
    "- Negativas - Representadas por 0\n",
    "- Neutras - Representadas por 1\n",
    "- Positivas - Representadas por 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel = pd.read_excel(\"Nintendo.xlsx\", sheet_name=\"Treinamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando Excel em 3 textos divididos por categoria\n",
    "\n",
    "trein_cat = []\n",
    "QTD_CAT = 3\n",
    "for i in range(0,QTD_CAT):\n",
    "    trein_cat.append(\" \".join(Excel[Excel[\"Classificação\"]==i].Treinamento))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.615238\n",
       "2    0.266667\n",
       "0    0.118095\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel[\"Classificação\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Três'textões' após a limpeza\n",
    "\n",
    "cat_clean = []\n",
    "serie = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    cat_clean.append(cleanup(trein_cat[i]))\n",
    "    serie.append(pd.Series(cat_clean[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo = \"\"\n",
    "for cat in cat_clean:\n",
    "    tudo += cat\n",
    "serie_tudo = pd.Series(tudo.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_abs = []\n",
    "freq_rel = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    freq_abs.append(serie[i].value_counts())\n",
    "    freq_rel.append(serie[i].value_counts(True))\n",
    "\n",
    "freq_abs_tudo = (serie_tudo.value_counts())\n",
    "freq_rel_tudo = (serie_tudo.value_counts(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probs = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    Probs.append(freq_abs[i].sum()/freq_abs_tudo.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_=[]\n",
    "for i in range(0,QTD_CAT):\n",
    "    set_.append(set(freq_rel[i].index))\n",
    "x = itertools.combinations(range(0,QTD_CAT),2)\n",
    "inter = []\n",
    "for i in x:\n",
    "    i0=i[0]\n",
    "    i1=i[1]\n",
    "    inter.append(set_[i0].intersection(set_[i1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador(tweet,freq_abs,qtdcat,freq_ab,prob):\n",
    "    categoria = 0\n",
    "    maior_prob = 0\n",
    "    Prob_Tweet_Categoria = {}\n",
    "    Prob_Categoria_Tweet = {}\n",
    "    for n in range(0,qtdcat):\n",
    "        probabilidade = 1\n",
    "        probtc = freq_abs[n][tweet.values]\n",
    "        for palavra,quantidade in probtc.items():\n",
    "            if np.isnan(quantidade) == True:\n",
    "                laplace = 1/(len(freq_ab)+len(freq_abs[n]))\n",
    "            else:\n",
    "                laplace = (quantidade+1)/(len(freq_ab)+len(freq_abs[n]))\n",
    "          \n",
    "            probabilidade *= laplace \n",
    "            \n",
    "        Prob_Tweet_Categoria[n] = probabilidade\n",
    "    for n in range(0,qtdcat):\n",
    "        prtoct = (Prob_Tweet_Categoria[n])*(prob[n])\n",
    "        Prob_Categoria_Tweet[n] = prtoct\n",
    "    for categorias, probab in Prob_Categoria_Tweet.items():\n",
    "        if probab > maior_prob:\n",
    "            maior_prob = probab\n",
    "            categoria = categorias\n",
    "    \n",
    "    return categoria\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada do Tweet\n",
    "def Limpa_Tweet(Excel_Lido,Coluna,freq_rel,qtdcat,freq_ab,prob):\n",
    "    indice = 0\n",
    "    Excel_Lido.loc[:,\"Classificação\"] = 0\n",
    "    for tweets in Excel_Lido.Teste:\n",
    "        tweet_limpo = cleanup(tweets.lower())\n",
    "        tweet = pd.Series(tweet_limpo.split())\n",
    "        classificado = Classificador(tweet,freq_rel,qtdcat,freq_ab,prob)\n",
    "        Excel_Lido.loc[indice,\"Classificação\"] = classificado\n",
    "        indice +=1\n",
    "    return Excel_Lido\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Excel_Teste = pd.read_excel(\"Nintendo.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "Excel_Fixo = Excel_Teste\n",
    "\n",
    "manual =[]\n",
    "for classficacao in Excel_Teste[\"Classificação\"]:\n",
    "    manual.append(classficacao)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.448929531325091e-67\n",
    "teste = \"Teste\"\n",
    "Excel_Classificado = Limpa_Tweet(Excel_Teste,teste,freq_abs,QTD_CAT,freq_abs_tudo,Probs)\n",
    "Excel_Classificado;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = []\n",
    "for classficacao in Excel_Classificado[\"Classificação\"]:\n",
    "    classificador.append(classficacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total': {'Certo': 251, 'Errado': 149}, 0: {'Certo': 1, 'Errado': 46}, 1: {'Certo': 230, 'Errado': 8}, 2: {'Certo': 20, 'Errado': 95}}\n",
      "{'Total': 0.6275, 0: 0.02127659574468085, 1: 0.9663865546218487, 2: 0.17391304347826086}\n"
     ]
    }
   ],
   "source": [
    "Teste_de_Performance = {\"Total\":{\"Certo\":0,\"Errado\":0},0:{\"Certo\":0,\"Errado\":0},1:{\"Certo\":0,\"Errado\":0},2:{\"Certo\":0,\"Errado\":0}}\n",
    "\n",
    "for i in range(len(manual)):\n",
    "    if classificador[i] == manual[i]:\n",
    "        Teste_de_Performance[manual[i]][\"Certo\"]+=1\n",
    "        Teste_de_Performance[\"Total\"][\"Certo\"]+=1\n",
    "    else:\n",
    "        Teste_de_Performance[manual[i]][\"Errado\"]+=1\n",
    "        Teste_de_Performance[\"Total\"][\"Errado\"]+=1\n",
    "            \n",
    "    \n",
    "    \n",
    "print(Teste_de_Performance)\n",
    "Porcentagem_de_Acerto ={}\n",
    "\n",
    "for categoria in Teste_de_Performance:\n",
    "    if Teste_de_Performance[categoria][\"Certo\"]!=0 and Teste_de_Performance[categoria][\"Certo\"]!=0:\n",
    "        Porcentagem_de_Acerto[categoria] = Teste_de_Performance[categoria][\"Certo\"]/(Teste_de_Performance[categoria][\"Certo\"]+Teste_de_Performance[categoria][\"Errado\"])\n",
    "print(Porcentagem_de_Acerto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda tentativa de criação do classificador\n",
    "Devido a problemas na distribuição da classificação dos tweets tanto na base de treinamento quanto no teste, foi necessário juntar duas categorias, a categoria 0 e 2, que eram respectivamente positivos e negativos, as quais serão agrupadas em um categoria que será chamada de opiniões,  e numerada com 0, enquanto a categoria 1 continuará sendo chamada de neutros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel2 = pd.read_excel(\"Nintendo2.xlsx\", sheet_name=\"Treinamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando Excel em 3 textos divididos por categoria\n",
    "\n",
    "trein_cat2 = []\n",
    "QTD_CAT2 = 2\n",
    "for i in range(0,QTD_CAT2):\n",
    "    trein_cat2.append(\" \".join(Excel2[Excel2[\"Classificação\"]==i].Treinamento))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.597774\n",
       "0    0.402226\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel2[\"Classificação\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'textões' após a limpeza\n",
    "\n",
    "cat_clean2 = []\n",
    "serie2 = []\n",
    "for i in range(0,QTD_CAT2):\n",
    "    cat_clean2.append(cleanup(trein_cat2[i]))\n",
    "    serie2.append(pd.Series(cat_clean2[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo2 = \"\"\n",
    "for cat in cat_clean2:\n",
    "    tudo2 += cat\n",
    "serie_tudo2 = pd.Series(tudo2.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_abs2 = []\n",
    "freq_rel2 = []\n",
    "for i in range(0,QTD_CAT2):\n",
    "    freq_abs2.append(serie2[i].value_counts())\n",
    "    freq_rel2.append(serie2[i].value_counts(True))\n",
    "\n",
    "freq_abs_tudo2 = (serie_tudo2.value_counts())\n",
    "freq_rel_tudo2 = (serie_tudo2.value_counts(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probs2 = []\n",
    "for i in range(0,QTD_CAT2):\n",
    "    Probs2.append(freq_abs2[i].sum()/freq_abs_tudo2.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_2=[]\n",
    "for i in range(0,QTD_CAT2):\n",
    "    set_2.append(set(freq_rel2[i].index))\n",
    "x = itertools.combinations(range(0,QTD_CAT2),2)\n",
    "inter2 = []\n",
    "for i in x:\n",
    "    i02=i[0]\n",
    "    i12=i[1]\n",
    "    inter2.append(set_2[i02].intersection(set_2[i12]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel_Teste2 = pd.read_excel(\"Nintendo2.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "\n",
    "\n",
    "manual2 =[]\n",
    "for classficacao in Excel_Teste2[\"Classificação\"]:\n",
    "    manual2.append(classficacao)\n",
    "\n",
    "\n",
    "teste = \"Teste\"\n",
    "Excel_Classificado2 = Limpa_Tweet(Excel_Teste2,teste,freq_abs2,QTD_CAT2,freq_abs_tudo2,Probs2)\n",
    "Excel_Classificado2;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classificador2 = []\n",
    "for classficacao in Excel_Classificado2[\"Classificação\"]:\n",
    "    classificador2.append(classficacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total': {'Certo': 298, 'Errado': 108}, 0: {'Certo': 85, 'Errado': 81}, 1: {'Certo': 213, 'Errado': 27}}\n",
      "{'Total': 0.7339901477832512, 0: 0.5120481927710844, 1: 0.8875}\n"
     ]
    }
   ],
   "source": [
    "Teste_de_Performance2 = {\"Total\":{\"Certo\":0,\"Errado\":0},0:{\"Certo\":0,\"Errado\":0},1:{\"Certo\":0,\"Errado\":0}}\n",
    "\n",
    "for i in range(len(manual2)):\n",
    "    if classificador2[i] == manual2[i]:\n",
    "        Teste_de_Performance2[manual2[i]][\"Certo\"]+=1\n",
    "        Teste_de_Performance2[\"Total\"][\"Certo\"]+=1\n",
    "    else:\n",
    "        Teste_de_Performance2[manual2[i]][\"Errado\"]+=1\n",
    "        Teste_de_Performance2[\"Total\"][\"Errado\"]+=1\n",
    "            \n",
    "    \n",
    "    \n",
    "print(Teste_de_Performance2)\n",
    "Porcentagem_de_Acerto2 ={}\n",
    "\n",
    "for categoria in Teste_de_Performance2:\n",
    "    if Teste_de_Performance2[categoria][\"Certo\"]!=0 and Teste_de_Performance2[categoria][\"Certo\"]!=0:\n",
    "        Porcentagem_de_Acerto2[categoria] = Teste_de_Performance2[categoria][\"Certo\"]/(Teste_de_Performance2[categoria][\"Certo\"]+Teste_de_Performance2[categoria][\"Errado\"])\n",
    "print(Porcentagem_de_Acerto2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa com quatro categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel3 = pd.read_excel(\"Nintendo3.xlsx\", sheet_name=\"Treinamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando Excel em 3 textos divididos por categoria\n",
    "\n",
    "trein_cat3 = []\n",
    "QTD_CAT3 = 4\n",
    "for i in range(0,QTD_CAT3):\n",
    "    trein_cat3.append(\" \".join(Excel3[Excel3[\"Classificação\"]==i].Treinamento))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.453543\n",
       "2    0.281890\n",
       "3    0.148031\n",
       "0    0.116535\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel3[\"Classificação\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'textões' após a limpeza\n",
    "\n",
    "cat_clean3 = []\n",
    "serie3 = []\n",
    "for i in range(0,QTD_CAT3):\n",
    "    cat_clean3.append(cleanup(trein_cat3[i]))\n",
    "    serie3.append(pd.Series(cat_clean3[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo3 = \"\"\n",
    "for cat in cat_clean3:\n",
    "    tudo3 += cat\n",
    "serie_tudo3 = pd.Series(tudo3.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_abs3 = []\n",
    "freq_rel3 = []\n",
    "for i in range(0,QTD_CAT3):\n",
    "    freq_abs3.append(serie3[i].value_counts())\n",
    "    freq_rel3.append(serie3[i].value_counts(True))\n",
    "\n",
    "freq_abs_tudo3 = (serie_tudo3.value_counts())\n",
    "freq_rel_tudo3 = (serie_tudo3.value_counts(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probs3 = []\n",
    "for i in range(0,QTD_CAT3):\n",
    "    Probs3.append(freq_abs3[i].sum()/freq_abs_tudo3.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_3=[]\n",
    "for i in range(0,QTD_CAT3):\n",
    "    set_3.append(set(freq_rel3[i].index))\n",
    "x = itertools.combinations(range(0,QTD_CAT3),2)\n",
    "inter3 = []\n",
    "for i in x:\n",
    "    i03=i[0]\n",
    "    i13=i[1]\n",
    "    inter3.append(set_3[i03].intersection(set_3[i13]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel_Teste3 = pd.read_excel(\"Nintendo3.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "\n",
    "\n",
    "manual3 =[]\n",
    "for classficacao in Excel_Teste3[\"Classificação\"]:\n",
    "    manual3.append(classficacao)\n",
    "\n",
    "\n",
    "\n",
    "teste = \"Teste\"\n",
    "Excel_Classificado3 = Limpa_Tweet(Excel_Teste3,teste,freq_abs3,QTD_CAT3,freq_abs_tudo3,Probs3)\n",
    "Excel_Classificado3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 3, 2, 1, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 2, 3, 1, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 3, 3, 1, 3, 1, 1, 2, 3, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 1, 3, 3, 1, 3, 1, 2, 3, 2, 2, 1, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 2, 1, 3, 3, 1, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "classificador3 = []\n",
    "for classficacao in Excel_Classificado3[\"Classificação\"]:\n",
    "    classificador3.append(classficacao)\n",
    "print(classificador3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total': {'Certo': 223, 'Errado': 177}, 0: {'Certo': 1, 'Errado': 47}, 1: {'Certo': 131, 'Errado': 22}, 2: {'Certo': 46, 'Errado': 72}, 3: {'Certo': 45, 'Errado': 36}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-c7e0b576343e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcategoria\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTeste_de_Performance3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mTeste_de_Performance3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategoria\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Certo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mTeste_de_Performance3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategoria\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Certo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mPorcentagem_de_Acerto3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategoria\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTeste_de_Performance3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategoria\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Certo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTeste_de_Performance3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategoria\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Certo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mTeste_de_Performance2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategoria\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Errado\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPorcentagem_de_Acerto3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "Teste_de_Performance3 = {\"Total\":{\"Certo\":0,\"Errado\":0},0:{\"Certo\":0,\"Errado\":0},1:{\"Certo\":0,\"Errado\":0},2:{\"Certo\":0,\"Errado\":0},3:{\"Certo\":0,\"Errado\":0}}\n",
    "\n",
    "for i in range(len(manual3)):\n",
    "    if classificador3[i] == manual3[i]:\n",
    "        Teste_de_Performance3[manual3[i]][\"Certo\"]+=1\n",
    "        Teste_de_Performance3[\"Total\"][\"Certo\"]+=1\n",
    "    else:\n",
    "        Teste_de_Performance3[manual3[i]][\"Errado\"]+=1\n",
    "        Teste_de_Performance3[\"Total\"][\"Errado\"]+=1\n",
    "            \n",
    "    \n",
    "    \n",
    "print(Teste_de_Performance3)\n",
    "Porcentagem_de_Acerto3 ={\"Total\":0,1:0}\n",
    "\n",
    "for categoria in Teste_de_Performance3:\n",
    "    if Teste_de_Performance3[categoria][\"Certo\"]!=0 and Teste_de_Performance3[categoria][\"Certo\"]!=0:\n",
    "        Porcentagem_de_Acerto3[categoria] = ((Teste_de_Performance3[categoria][\"Certo\"])/(Teste_de_Performance3[categoria][\"Certo\"]+Teste_de_Performance2[categoria][\"Errado\"]))\n",
    "print(Porcentagem_de_Acerto3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando os percentuais de acerto obtidos podemos concluir que o classificador funciona bem para quando existem apenas duas categorias, visto que a base de dados que foi obtida tem um numero quase igual de tweets classificados como 0 e 1.\n",
    "\n",
    "Porém quando são usadas 3 categorias, o classificador na maioria das vezes classifica os tweets como 1, isso se deve ao tamanho da base de dados que ele possui, onde  os tweets são classificados como neutros majoritariamente, mostrando assim a tendência do tipo de tweets feito sobre a empresa \"Nintendo\" e deixando o classificador com uma tendência que implica numa piora do seu rendimento\n",
    "\n",
    "Para 4 categorias..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porque não podemos utilizar o próprio classificador para gerar mais amostras de treinamento?\n",
    "Essa é uma pergunta que pode surgir quando se está fazendo um classificador, e apesar disso parecer uma boa ideia, esse método pode estragar seu classificador, uma vez que o intuito de gerar mais amostra de treinamento é justamente melhorar o classificador, uma vez que ele não é perfeito e pode cometer erros.\n",
    "\n",
    "Se o classificador for utilizado para gerar mais amostras, ele vai acabar repetindo os seus erros mais comuns e ficar cada vez mais longe de ser um bom classificador, o processo de geração de amostras de treinamento deve ser feito manualmente, assim deixando o classificador cada vez mais eficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propondo diferentes cenários para o Naive Bayes\n",
    "\n",
    "Como proposta de outras situações possíveis para o uso do Naive Bayes, poderiamos citar por exemplo, a classificação de posts no facebook por uma empresa de eventos, a fim de receber feedbacks em relação ao útimo show realizado pela companhia. Assim poderia propor melhorias e aperfeiçoar o serviço, atraindo mais clientes e portanto, mais capital. \n",
    "\n",
    "Outro cenário possível seria a utilização do Naive Bayes para classifcar as respostas de um pequeno formulário preenchido pelos clientes do restaurante a respeito do atendimento, assim o gerente conseguiria saber a satisfação de seus clientes, e tomar decisões como por exemplo, demitir seus funcionários.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugerindo e explicando possíveis melhorias para o projeto\n",
    "\n",
    "Uma melhoria que poderia ajudar o nosso classificador a aumentar a taxa de acerto seria elevar o número de tweets presentes na base, além de manter uma distribuição proporcional entre as categorias nas respectivas bases, treinamento e teste.\n",
    "\n",
    "Outra melhoria possível seria ensinar o classificador a classificar emojis da seguinte maneira:\n",
    "    1 - Fariamos uma lista de emojis; \n",
    "    2 - Classificariamos os principais emojis em relação as categorias escolhidas;\n",
    "    3 - Fariamos uma função para que, durante a classificação dos tweets, o classificador consultasse a lista de emojis e colocasse o resultado de acordo com a mesma.\n",
    "\n",
    "Utilizar algum software ou programa terceirizado para aumentar o número de amostras da base e diminuir o trabalho manual para isso\n",
    "\n",
    "Outra melhoria seria analisar os links que estão presentes em alguns tweets, e existem duas possibilidades para isso, ou exclui-los dos tweets, para que não interferissem na análise ou, a solução que seria ideal, utilizar algum software ou módulo do python que pudesse ver para onde os links iriam direcionar quem lesse o tweet, e se fosse um gif ou imagem, substituir o link pelas palvaras chaves que a descrevem e utilizá-las para o cálculo da probabilidade, assim tendo uma base de dados mais completa e melhorando o classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
