{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _____\n",
    "\n",
    "Nome: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "#Conta: @gabrielpfm\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "#with open('auth.pass') as fp:    \n",
    " #   data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "#auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "#auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "#produto = 'Nintendo'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "#n = 750\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 450\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-11ef86320922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Cria um objeto para a captura\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Inicia a captura, para mais detalhes: ver a documentação do tweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#i = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'auth' is not defined"
     ]
    }
   ],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "#i = 1\n",
    "#msgs = []\n",
    "#for msg in tweepy.Cursor(api.search, q=produto, lang=lang,tweet_mode=\"extended\").items():    \n",
    "    #msgs.append(msg.full_text.lower())\n",
    " #   i += 1\n",
    " # #  if i > n:\n",
    "   #     break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "#shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "#if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "   # writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "  #  dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "   # dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "  #  dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "  #  dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "  #  writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel = pd.read_excel(\"Nintendo.xlsx\", sheet_name=\"Treinamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando Excel em 3 textos divididos por categoria\n",
    "trein_cat0 = \" \".join(Excel[Excel[\"Classificação\"]==0].Treinamento)\n",
    "trein_cat1 = \" \".join(Excel[Excel[\"Classificação\"]==1].Treinamento)\n",
    "trein_cat2 = \" \".join(Excel[Excel[\"Classificação\"]==2].Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Três'textões' após a limpeza\n",
    "cat0_clean = cleanup(trein_cat0.lower())\n",
    "serie0 = pd.Series(cat0_clean.split())\n",
    "cat1_clean = cleanup(trein_cat1.lower())\n",
    "serie1 = pd.Series(cat1_clean.split())\n",
    "cat2_clean = cleanup(trein_cat2.lower())\n",
    "serie2 = pd.Series(cat2_clean.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_abs0 = serie0.value_counts()\n",
    "freq_abs1 = serie1.value_counts()\n",
    "freq_abs2 = serie2.value_counts()\n",
    "freq_rel0 = serie0.value_counts(True)\n",
    "freq_rel1 = serie1.value_counts(True)\n",
    "freq_rel2 = serie2.value_counts(True)\n",
    "freq_rel = [freq_rel0,freq_rel1,freq_rel2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo = cat0_clean+cat1_clean+cat2_clean\n",
    "serie_tudo = pd.Series(tudo.split())\n",
    "freq_abs_tudo = serie_tudo.value_counts()\n",
    "freq_rel_tudo = serie_tudo.value_counts(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prob_0 = freq_abs0.sum()/freq_abs_tudo.sum()\n",
    "Prob_1 = freq_abs1.sum()/freq_abs_tudo.sum()\n",
    "Prob_2 = freq_abs2.sum()/freq_abs_tudo.sum()\n",
    "Probs = [Prob_0,Prob_1,Prob_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set0 = set(freq_rel0.index)\n",
    "set1 = set(freq_rel1.index)\n",
    "set2 = set(freq_rel2.index)\n",
    "inter01 = set0.intersection(set1)\n",
    "inter02 = set0.intersection(set2)\n",
    "inter12 = set1.intersection(set2)\n",
    "inter012 = set0.intersection(inter12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador(tweet,freq_rel):\n",
    "    categoria = 0\n",
    "    maior_prob = 48765665847676\n",
    "    Prob_Tweet_Categoria = {}\n",
    "    Prob_Categoria_Tweet = {}\n",
    "    for n in range(0,3):\n",
    "        probtc = freq_rel[n][tweet.values]\n",
    "        Prob_Tweet_Categoria[n] = probtc.prod()\n",
    "    for n in range(0,3):\n",
    "        prtoct = Prob_Tweet_Categoria[n]*Probs[n]\n",
    "        Prob_Categoria_Tweet[n] = prtoct\n",
    "    for categorias, probabilidade in Prob_Categoria_Tweet.items():\n",
    "        if probabilidade < maior_prob:\n",
    "            maior_prob = probabilidade\n",
    "            \n",
    "            categoria = categorias\n",
    "    return categoria\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada do Tweet\n",
    "def Limpa_Tweet(Excel_Lido,Coluna,freq_rel):\n",
    "    indice = 0\n",
    "    Excel_Lido.loc[:,\"Classificação\"] = 0\n",
    "    for tweets in Excel_Lido.Teste:\n",
    "        tweet_limpo = cleanup(tweets.lower())\n",
    "        tweet = pd.Series(tweet_limpo.split())\n",
    "        classificado = Classificador(tweet,freq_rel)\n",
    "        Excel_Lido.loc[indice,\"Classificação\"] = classificado\n",
    "        indice +=1\n",
    "    return Excel_Lido\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel_Teste = pd.read_excel(\"Nintendo.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "manual =[]\n",
    "for classficacao in Excel_Teste[\"Classificação\"]:\n",
    "    manual.append(classficacao)\n",
    "\n",
    "\n",
    "teste = \"Teste\"\n",
    "Excel_Classificado = Limpa_Tweet(Excel_Teste,teste,freq_rel)\n",
    "Excel_Classificado;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = []\n",
    "for classficacao in Excel_Classificado[\"Classificação\"]:\n",
    "    classificador.append(classficacao)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Certo': 201, 'Errado': 199}\n"
     ]
    }
   ],
   "source": [
    "Teste_de_Performance = {\"Certo\":0,\"Errado\":0}\n",
    "for i in range(len(manual)):\n",
    "    if classificador[i] == manual[i]:\n",
    "        Teste_de_Performance[\"Certo\"]+=1\n",
    "    else:\n",
    "        Teste_de_Performance[\"Errado\"]+=1\n",
    "print(Teste_de_Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
