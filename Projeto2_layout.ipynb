{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Gabriel Pascua de Freitas Moreira\n",
    "\n",
    "Nome: Fernando Cesar Furtado Ballesteros Fincatti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "#Conta: @gabrielpfm\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "#with open('auth.pass') as fp:    \n",
    " #   data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "#auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "#auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "#produto = 'Nintendo'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "#n = 750\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 450\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "#i = 1\n",
    "#msgs = []\n",
    "#for msg in tweepy.Cursor(api.search, q=produto, lang=lang,tweet_mode=\"extended\").items():    \n",
    "    #msgs.append(msg.full_text.lower())\n",
    " #   i += 1\n",
    " # #  if i > n:\n",
    "   #     break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "#shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "#if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "   # writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "  #  dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "   # dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "  #  dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "  #  dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "  #  writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel = pd.read_excel(\"Nintendo.xlsx\", sheet_name=\"Treinamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando Excel em 3 textos divididos por categoria\n",
    "\n",
    "trein_cat = []\n",
    "QTD_CAT = 3\n",
    "for i in range(0,QTD_CAT):\n",
    "    trein_cat.append(\" \".join(Excel[Excel[\"Classificação\"]==i].Treinamento))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.615238\n",
       "2    0.266667\n",
       "0    0.118095\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel[\"Classificação\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Três'textões' após a limpeza\n",
    "\n",
    "cat_clean = []\n",
    "serie = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    cat_clean.append(cleanup(trein_cat[i]))\n",
    "    serie.append(pd.Series(cat_clean[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo = \"\"\n",
    "for cat in cat_clean:\n",
    "    tudo += cat\n",
    "serie_tudo = pd.Series(tudo.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_abs = []\n",
    "freq_rel = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    freq_abs.append(serie[i].value_counts())\n",
    "    freq_rel.append(serie[i].value_counts(True))\n",
    "\n",
    "freq_abs_tudo = (serie_tudo.value_counts())\n",
    "freq_rel_tudo = (serie_tudo.value_counts(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probs = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    Probs.append(freq_abs[i].sum()/freq_abs_tudo.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_=[]\n",
    "for i in range(0,QTD_CAT):\n",
    "    set_.append(set(freq_rel[i].index))\n",
    "x = itertools.combinations(range(0,QTD_CAT),2)\n",
    "inter = []\n",
    "for i in x:\n",
    "    i0=i[0]\n",
    "    i1=i[1]\n",
    "    inter.append(set_[i0].intersection(set_[i1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador(tweet,freq_abs):\n",
    "    categoria = 0\n",
    "    maior_prob = 0\n",
    "    Prob_Tweet_Categoria = {}\n",
    "    Prob_Categoria_Tweet = {}\n",
    "    for n in range(0,3):\n",
    "        probabilidade = 1\n",
    "        probtc = freq_abs[n][tweet.values]\n",
    "        for palavra,quantidade in probtc.items():\n",
    "\n",
    "\n",
    "            if np.isnan(quantidade) == True:\n",
    "                laplace = 1/(len(freq_abs_tudo)+len(freq_abs[n]))\n",
    "            else:\n",
    "                laplace = quantidade+1/(len(freq_abs_tudo)+len(freq_abs[n]))\n",
    "                \n",
    "        probabilidade *= laplace   \n",
    "        Prob_Tweet_Categoria[n] = probabilidade\n",
    "    for n in range(0,3):\n",
    "        prtoct = Prob_Tweet_Categoria[n]*Probs[n]\n",
    "        Prob_Categoria_Tweet[n] = prtoct\n",
    "    for categorias, probabilidade in Prob_Categoria_Tweet.items():\n",
    "        if probabilidade > maior_prob:\n",
    "            maior_prob = probabilidade\n",
    "            \n",
    "            categoria = categorias\n",
    "    \n",
    "    return categoria\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada do Tweet\n",
    "def Limpa_Tweet(Excel_Lido,Coluna,freq_rel):\n",
    "    indice = 0\n",
    "    Excel_Lido.loc[:,\"Classificação\"] = 0\n",
    "    for tweets in Excel_Lido.Teste:\n",
    "        tweet_limpo = cleanup(tweets.lower())\n",
    "        tweet = pd.Series(tweet_limpo.split())\n",
    "        classificado = Classificador(tweet,freq_rel)\n",
    "        Excel_Lido.loc[indice,\"Classificação\"] = classificado\n",
    "        indice +=1\n",
    "    return Excel_Lido\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel_Teste = pd.read_excel(\"Nintendo.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "manual =[]\n",
    "for classficacao in Excel_Teste[\"Classificação\"]:\n",
    "    manual.append(classficacao)\n",
    "\n",
    "\n",
    "teste = \"Teste\"\n",
    "Excel_Classificado = Limpa_Tweet(Excel_Teste,teste,freq_abs)\n",
    "Excel_Classificado;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.9375\n",
       "2    0.0500\n",
       "0    0.0125\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel_Teste[\"Classificação\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = []\n",
    "for classficacao in Excel_Classificado[\"Classificação\"]:\n",
    "    classificador.append(classficacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total': {'Certo': 249, 'Errado': 151}, 0: {'Certo': 2, 'Errado': 3}, 1: {'Certo': 234, 'Errado': 141}, 2: {'Certo': 13, 'Errado': 7}}\n",
      "{'Total': 0.6225, 0: 0.4, 1: 0.624, 2: 0.65}\n"
     ]
    }
   ],
   "source": [
    "Teste_de_Performance = {\"Total\":{\"Certo\":0,\"Errado\":0},0:{\"Certo\":0,\"Errado\":0},1:{\"Certo\":0,\"Errado\":0},2:{\"Certo\":0,\"Errado\":0}}\n",
    "\n",
    "for i in range(len(manual)):\n",
    "    if classificador[i] == manual[i]:\n",
    "        Teste_de_Performance[classificador[i]][\"Certo\"]+=1\n",
    "        Teste_de_Performance[\"Total\"][\"Certo\"]+=1\n",
    "    else:\n",
    "        Teste_de_Performance[classificador[i]][\"Errado\"]+=1\n",
    "        Teste_de_Performance[\"Total\"][\"Errado\"]+=1\n",
    "            \n",
    "    \n",
    "    \n",
    "print(Teste_de_Performance)\n",
    "Porcentagem_de_Acerto ={}\n",
    "\n",
    "for categoria in Teste_de_Performance:\n",
    "    if Teste_de_Performance[categoria][\"Certo\"]!=0 and Teste_de_Performance[categoria][\"Certo\"]!=0:\n",
    "        Porcentagem_de_Acerto[categoria] = Teste_de_Performance[categoria][\"Certo\"]/(Teste_de_Performance[categoria][\"Certo\"]+Teste_de_Performance[categoria][\"Errado\"])\n",
    "print(Porcentagem_de_Acerto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda tentativa da criação do classificador\n",
    "Devido a problemas na distribuição dos tweets entre a base de treinamento e teste, onde a proporção da categorira 1 era de 60% no treinamento e 93% no teste, iremos fazer uma distribuição manual dos tweets para que a base seja proporcional em ralação às categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel2 = pd.read_excel(\"Nintendo2.xlsx\", sheet_name=\"Treinamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando Excel em 3 textos divididos por categoria\n",
    "\n",
    "trein_cat2 = []\n",
    "QTD_CAT = 3\n",
    "for i in range(0,QTD_CAT):\n",
    "    trein_cat2.append(\" \".join(Excel2[Excel2[\"Classificação\"]==i].Treinamento))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.615238\n",
       "2    0.266667\n",
       "0    0.118095\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel2[\"Classificação\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Três'textões' após a limpeza\n",
    "\n",
    "cat_clean2 = []\n",
    "serie2 = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    cat_clean2.append(cleanup(trein_cat2[i]))\n",
    "    serie2.append(pd.Series(cat_clean2[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo2 = \"\"\n",
    "for cat in cat_clean2:\n",
    "    tudo2 += cat\n",
    "serie_tudo2 = pd.Series(tudo2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_abs2 = []\n",
    "freq_rel2 = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    freq_abs2.append(serie2[i].value_counts())\n",
    "    freq_rel2.append(serie2[i].value_counts(True))\n",
    "\n",
    "freq_abs_tudo2 = (serie_tudo2.value_counts())\n",
    "freq_rel_tudo2 = (serie_tudo2.value_counts(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probs2 = []\n",
    "for i in range(0,QTD_CAT):\n",
    "    Probs2.append(freq_abs2[i].sum()/freq_abs_tudo2.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_2=[]\n",
    "for i in range(0,QTD_CAT):\n",
    "    set_2.append(set(freq_rel2[i].index))\n",
    "x = itertools.combinations(range(0,QTD_CAT),2)\n",
    "inter2 = []\n",
    "for i in x:\n",
    "    i02=i[0]\n",
    "    i12=i[1]\n",
    "    inter.append(set_[i02].intersection(set_[i12]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador(tweet,freq_abs):\n",
    "    categoria = 0\n",
    "    maior_prob = 0\n",
    "    Prob_Tweet_Categoria = {}\n",
    "    Prob_Categoria_Tweet = {}\n",
    "    for n in range(0,3):\n",
    "        probabilidade = 1\n",
    "        probtc = freq_abs[n][tweet.values]\n",
    "        for palavra,quantidade in probtc.items():\n",
    "\n",
    "\n",
    "            if np.isnan(quantidade) == True:\n",
    "                laplace = 1/(len(freq_abs_tudo)+len(freq_abs[n]))\n",
    "            else:\n",
    "                laplace = quantidade+1/(len(freq_abs_tudo)+len(freq_abs[n]))\n",
    "                \n",
    "        probabilidade *= laplace   \n",
    "        Prob_Tweet_Categoria[n] = probabilidade\n",
    "    for n in range(0,3):\n",
    "        prtoct = Prob_Tweet_Categoria[n]*Probs[n]\n",
    "        Prob_Categoria_Tweet[n] = prtoct\n",
    "    for categorias, probabilidade in Prob_Categoria_Tweet.items():\n",
    "        if probabilidade > maior_prob:\n",
    "            maior_prob = probabilidade\n",
    "            \n",
    "            categoria = categorias\n",
    "    \n",
    "    return categoria\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada do Tweet\n",
    "def Limpa_Tweet(Excel_Lido,Coluna,freq_rel):\n",
    "    indice = 0\n",
    "    Excel_Lido.loc[:,\"Classificação\"] = 0\n",
    "    for tweets in Excel_Lido.Teste:\n",
    "        tweet_limpo = cleanup(tweets.lower())\n",
    "        tweet = pd.Series(tweet_limpo.split())\n",
    "        classificado = Classificador(tweet,freq_rel)\n",
    "        Excel_Lido.loc[indice,\"Classificação\"] = classificado\n",
    "        indice +=1\n",
    "    return Excel_Lido\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel_Teste2 = pd.read_excel(\"Nintendo2.xlsx\", sheet_name=\"Teste\")\n",
    "\n",
    "manual2 =[]\n",
    "for classficacao in Excel_Teste2[\"Classificação\"]:\n",
    "    manual2.append(classficacao)\n",
    "\n",
    "\n",
    "teste = \"Teste\"\n",
    "Excel_Classificado2 = Limpa_Tweet(Excel_Teste2,teste,freq_abs2)\n",
    "Excel_Classificado2;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.9375\n",
       "2    0.0500\n",
       "0    0.0125\n",
       "Name: Classificação, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel_Teste2[\"Classificação\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador2 = []\n",
    "for classficacao in Excel_Classificado2[\"Classificação\"]:\n",
    "    classificador2.append(classficacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total': {'Certo': 249, 'Errado': 151}, 0: {'Certo': 2, 'Errado': 3}, 1: {'Certo': 234, 'Errado': 141}, 2: {'Certo': 13, 'Errado': 7}}\n",
      "{'Total': 0.6225, 0: 0.4, 1: 0.624, 2: 0.65}\n"
     ]
    }
   ],
   "source": [
    "Teste_de_Performance2 = {\"Total\":{\"Certo\":0,\"Errado\":0},0:{\"Certo\":0,\"Errado\":0},1:{\"Certo\":0,\"Errado\":0},2:{\"Certo\":0,\"Errado\":0}}\n",
    "\n",
    "for i in range(len(manual)):\n",
    "    if classificador[i] == manual[i]:\n",
    "        Teste_de_Performance2[classificador[i]][\"Certo\"]+=1\n",
    "        Teste_de_Performance2[\"Total\"][\"Certo\"]+=1\n",
    "    else:\n",
    "        Teste_de_Performance2[classificador[i]][\"Errado\"]+=1\n",
    "        Teste_de_Performance2[\"Total\"][\"Errado\"]+=1\n",
    "            \n",
    "    \n",
    "    \n",
    "print(Teste_de_Performance2)\n",
    "Porcentagem_de_Acerto2 ={}\n",
    "\n",
    "for categoria in Teste_de_Performance:\n",
    "    if Teste_de_Performanc2e[categoria][\"Certo\"]!=0 and Teste_de_Performance2[categoria][\"Certo\"]!=0:\n",
    "        Porcentagem_de_Acerto2[categoria] = Teste_de_Performance2[categoria][\"Certo\"]/(Teste_de_Performance2[categoria][\"Certo\"]+Teste_de_Performance2[categoria][\"Errado\"])\n",
    "print(Porcentagem_de_Acerto2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando os percentuais de acerto obtidos podemos concluir que o classificador funciona bem para a categoria 1 e a categoria 2, neutro e positivo, respectivamente, enquanto para a categoria 0, negativo, ele ainda apresenta dificuldade em classificar.\n",
    "\n",
    "Isso se deve ao tamanho da base de dados que ele possui, onde  os tweets são classificados como neutros majoritariamente, mostrando assim a tendência do tipo de tweets feito sobre a empresa \"Nintendo\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porque não podemos utilizar o próprio classificador para gerar mais amostras de treinamento?\n",
    "Essa é uma pergunta que pode surgir quando se está fazendo um classificador, e apesar disso parecer uma boa ideia, esse método pode estragar seu classificador, uma vez que o intuito de gerar mais amostra de treinamento é justamente melhorar o classificador, uma vez que ele não é perfeito e pode cometer erros.\n",
    "\n",
    "Se o classificador for utilizado para gerar mais amostras, ele vai acabar repetindo os seus erros mais comuns e ficar cada vez mais longe de ser um bom classificador, o processo de geração de amostras de treinamento deve ser feito manualmente, assim deixando o classificador cada vez mais eficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
